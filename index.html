<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Aryan Mikaeili</title>
    <link href='http://fonts.googleapis.com/css?family=Josefin+Slab:600' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Exo' rel='stylesheet' type='text/css'>
    <!-- <link rel="shortcut icon" href="img/favicon.ico" type="image/x-icon">-->
    <!-- <link rel="icon" href="img/favicon.ico" type="image/x-icon"> -->
    <link rel="stylesheet" href="css/style.css">
  </head>

  <body>
  <header id = "header" class = "topbar">
    <h1>Aryan Mikaeili</h1>
    <nav>
      <ul>

        <li class="navbar-right"><a href=#home>Home</a></li>
        <li class="navbar-right"><a href=#hobbies>hobbies</a></li>
        <li class="navbar-right"><a href=#research>research</a></li>
        <li class="navbar-right"><a href=#bio>bio</a></li>
    </ul>
    </nav>

  </header>
  <div id = "home">
  </div>
  <div id = "first-section">
    <div id = "iconscontainer">

      <ul>
        <li><a target="_blank" href="http://github.com/aryanmikaeili/"><img src="img/github.svg"  class="icon"/></a></li>
        <li><a target="_blank" href="files/cv_AryanMikaeili2.pdf"><img src="img/resume.png" alt="resume" class="icon"/></a></li>


      </ul>

      <center>(last updated: 3 December 2020)</center>
      <center><a href="mailto:ar.mikaeili@yahoo.com">ar.mikaeili@yahoo.com</a></center>
      <center><a href="mailto:armikaeili@ce.sharif.edu">armikaeili@ce.sharif.edu</a></center>

    </div>

    <div id="bio">
    <h1> Bio </h1>
    <p>
      <img src="img/me2.jpg" width="300" height="300" style="margin-left: 30px; float:right; margin-top: 130px; margin-bottom: 10px; border-radius: 50%;" />
        Hello. My name is Aryan Mikaeili and I am currently a Computer Engineering B. Sc. student at <a href="http://www.en.sharif.edu/">Sharif University of Technology</a>.
      <br />
      I am a research assistant at the <a href="http://ipl.ce.sharif.edu/">Image processing lab (IPL)</a>, where under supervision of  <a href="http://sharif.ir/~kasaei">Prof. Shohreh Kasaei</a> I work on adversarial attacks on deep 3D point cloud models and geometric interpretability of these models.
      <br />
      I am mainly interested in 3D computer vision, robust deep learning and interpretability of deep networks. But, I am also interested in other topics in computer vision and machine learning such as generative models, human pose estimation, image segmentation and etc.
      <br />
    </p>
    </div>
  </div>
  <div id = "research">
    <div id = "research-text">
      <h1>Research experience</h1>
      <p>
          <span class="title">Image processing lab (IPL)</span>
          <span class="date">June 2020 - Present</span>
      </p>


    <!--<h2> Publications </h2>
    <br />-->
    <!--<h2> Preprints </h2>-->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody>
        <tr id='mbrladv'>
          <td width="30%">
            <img src="img/mbrladv-cover-img.png" width="100%">
          </td>
          <td valign="top" width="70%">
            <p>
              <a href="https://openreview.net/forum?id=SylL0krYPS">
                Toward Evaluating Robustness of Deep Reinforcement Learning with Continuous Control
              </a>
              <br>
               <a href=https://www.linkedin.com/in/tsui-wei-lily-weng-b27a937b/>Tsui-Wei Weng</a>, <a href=https://www.linkedin.com/in/krishnamurthy-dvijotham-09820146/>Krisnamurthy (Dj) Dvijotham</a>, <a href=https://www.linkedin.com/in/jonathan-uesato-16677788/>Jonathan Uesato</a>, <strong>Kai Xiao</strong>, <a href=https://www.linkedin.com/in/sgowal/>Sven Gowal</a>, <a href=https://www.linkedin.com/in/robert-stanforth-b2a68761/>Robert Stanforth</a>, <a href=https://www.linkedin.com/in/pushmeet-kohli-4838994/>Pushmeet Kohli</a>
              <br>
              <em>Proceedings of the International Conference on Learning Representations (ICLR)</em>, 2020
              <br>
            </p>
            <p>
              We study the problem of continuous control agents in deep RL with adversarial attacks and propose the first two-step attack algorithm based on learned model dynamics. Extensive experiments on various MuJoCo domains (Cartpole, Fish, Walker, Humanoid) demonstrate that our proposed framework is much more effective and efficient than model-free based attacks baselines in degrading agent performance and in driving agents to unsafe states.
            </p>
          </td>
        </tr>
        <tr id='randsmooth'>
          <td width="30%">
            <img src="img/randsmooth-cover-img.png" width="100%">
          </td>
          <td valign="top" width="70%">
            <p>
              <a href="https://openreview.net/forum?id=SJlKrkSFPH">
                A Framework for Robustness Certification of Smoothed Classifiers using f-divergences
              </a>
              <br>
               <a href=https://www.linkedin.com/in/krishnamurthy-dvijotham-09820146/>Krisnamurthy (Dj) Dvijotham</a>, <a href=http://www.homepages.ucl.ac.uk/~ucabaye/>Jamie Hayes</a>, <a href=https://www.linkedin.com/in/borja-balle-b616751b/>Borja Balle</a>, <a href=https://www.linkedin.com/in/zico-kolter-560382a4/>Zico Kolter</a>, <a href=https://www.linkedin.com/in/chongli-qin-b3b85059/>Chongli Qin</a>, <a href=https://www.linkedin.com/in/andras-gyorgy-a61477125/>Andras Gyorgy</a>, <strong>Kai Xiao</strong>, <a href=https://www.linkedin.com/in/sgowal/>Sven Gowal</a>,  <a href=https://www.linkedin.com/in/pushmeet-kohli-4838994/>Pushmeet Kohli</a>
              <br>
              <em>Proceedings of the International Conference on Learning Representations (ICLR)</em>, 2020
              <br>
            </p>
            <p>
              Past work on randomized smoothing, which can provide provable guarantees on the robustness of models, has focused on restricted classes of smoothing measures or perturbations (like Gaussian or discrete) and has only been able to prove robustness with respect to simple norm bounds. In this paper we introduce a general framework for proving robustness properties of smoothed machine learning models in the black-box setting.
            </p>
          </td>
        </tr>
        <tr id='ddrmpo'>
          <td width="30%">
            <img src="img/ddrmpo-cover-img.png" width="100%">
          </td>
          <td valign="top" width="70%">
            <p>
              <a href="https://sites.google.com/view/neurips19-safe-robust-workshop">
                Data-Driven Robust Reinforcement Learning for Continuous Control
              </a>
              <br>
               <a href=https://www.linkedin.com/in/yuanyuan-shi-bb734210a/>Yuanyuan Shi</a>, <strong>Kai Xiao</strong>, <a href=https://www.linkedin.com/in/daniel-mankowitz-96a25a46/>Daniel J. Mankowitz</a>, <a href=https://www.linkedin.com/in/rae-jeong-35291592/>Rae Jeong</a>, <a href=https://www.linkedin.com/in/levinir/>Nir Levine</a>, <a href=https://www.linkedin.com/in/sgowal/>Sven Gowal</a>, <a href=https://www.linkedin.com/in/timothy-mann-09a0531b/>Timothy Mann</a>, <a href=https://www.linkedin.com/in/todd-hester-606b6122/>Todd Hester</a>
              <br>
              <em>NeurIPS workshop on Safety and Robustness in Decision Making</em>, 2019
              <br>
            </p>
            <p>
              We  focus  on  learning  RL  policies  that  are  robust  to perturbations in the environment dynamics, which we refer to as model misspecification. The motivation is the case where we have access to a (possibly inaccurate) simulator and real world data. We propose Data-Driven Robust Maximum a-posteriori Policy Optimization (DDR-MPO), which first learns transition models with datasets collected from different perturbed environments, corresponding to the real world systems, and then uses these models along with the provided simulator to learn a robust policy.
            </p>
          </td>
        </tr>
        <tr id='advspec'>
          <td width="30%">
            <img src="img/advspec-cover-img.png" width="100%">
          </td>
          <td valign="top" width="70%">
            <p>
              <a href="https://sites.google.com/view/neurips19-safe-robust-workshop">
                Learning Neural Dynamics Simulators with Adversarial Specification Training
              </a>
              <br>
              <strong>Kai Xiao</strong>, <a href=https://www.linkedin.com/in/sgowal/>Sven Gowal</a>, <a href=https://www.linkedin.com/in/todd-hester-606b6122/>Todd Hester</a>, <a href=https://www.linkedin.com/in/rae-jeong-35291592/>Rae Jeong</a>, <a href=https://www.linkedin.com/in/daniel-mankowitz-96a25a46/>Daniel J. Mankowitz</a>, <a href=https://www.linkedin.com/in/yuanyuan-shi-bb734210a/>Yuanyuan Shi</a>, <a href=https://www.linkedin.com/in/tsui-wei-lily-weng-b27a937b/>Tsui-Wei Weng</a> 
              <br>
              <em>NeurIPS workshop on Safety and Robustness in Decision Making</em>, 2019
              <br>
            </p>
            <p>
              Learning an accurate dynamics simulator is important for effective model-based reinforcement learning (RL). Often, we have prior knowledge about the dynamics models we are trying to learn (e.g., physical laws like axes of symmetry must be respected). We focus on learning dynamics models that incorporate prior knowledge as model specifications (i.e., mathematical invariances that always hold true), and we enforce these specifications via adversarial training. Using specifications improves sample complexity and generalization.
            </p>
          </td>
        </tr>
        <tr id='rs'>
          <td width="30%">
            <img src="img/rs-cover-img.png" width="100%">
          </td>
          <td valign="top" width="70%">
            <p>
              <a href="https://arxiv.org/abs/1809.03008">
                Training for Faster Adversarial Robustness Verification via Inducing ReLU Stability
              </a>
              <br>
              <strong>Kai Xiao</strong>, <a href=https://www.linkedin.com/in/vincent-t-14243683/>Vincent Tjeng</a>, <a href=http://web.mit.edu/nshafiul/www/>Nur Muhammad (Mahi) Shafiullah</a>, <a href=https://people.csail.mit.edu/madry/>Aleksander Madry</a>
              <br>
              <em>Proceedings of the International Conference on Learning Representations (ICLR)</em>, 2019
              <br>
            </p>
            <p>
              This paper explores co-designing neural networks to be both robust and easily verifiable. The paper identifies two key properties of neural networks that make it more amenable to verification - weight sparsity and ReLU stability - and describes regularization methods to achieve these goals during training without significantly hurting the neural network's accuracy. These techniques can be used in conjunction with any standard training procedure, and they allows us to train provably robust networks for MNIST and CIFAR-10.
            </p>
          </td>
        </tr>
        <tr id='milp'>
          <td width="30%">
            <img src="img/milp-cover-img.png" width="100%" >
          </td>
          <td valign="top" width="70%">
            <p>
              <a href="https://arxiv.org/abs/1711.07356">
                Evaluating Robustness of Neural Networks with Mixed Integer Programming
              </a>
              <br>
              <a href=https://www.linkedin.com/in/vincent-t-14243683/>Vincent Tjeng</a>, <strong>Kai Xiao</strong>, <a href=https://groups.csail.mit.edu/locomotion/russt.html>Russ Tedrake</a>
              <br>
              <em>Proceedings of the International Conference on Learning Representations (ICLR)</em>, 2019
              <br>
            </p>
            <p>
              This paper leverages mixed integer linear programs to verify the robustness of neural networks in a speed that is two to three orders of magnitude quicker than the previous state-of-the-art. The computational speedup is achieved through tight formulations for non-linearities, as well as a novel presolve algorithm that makes full use of all information available. This allows us to verify the robustness of larger convolutional networks, and determine, for the first time, the exact adversarial accuracy of an MNIST classifier to norm-bounded perturbations.
            </p>
          </td>
        </tr>
        <tr id='cc'>
          <td width="30%">
            <img src="img/cc-cover-img.jpg" width="100%">
          </td>
          <td valign="top" width="70%">
            <p>
              <a href="https://arxiv.org/abs/1808.07540">
                Cookie Clicker
              </a>
              <br>
              <a href=http://erikdemaine.org/>Erik D. Demaine</a>, <a href=http://www.alg.cei.uec.ac.jp/itohiro/souran/itohiro-e.html>Hiro Ito</a>, <a href=http://www.ulb.ac.be/di/algo/sl/>Stefan Langerman</a>, <a href=https://www.linkedin.com/in/jayson-lynch-b6297ab/>Jayson Lynch</a>, <a href=https://www.researchgate.net/scientific-contributions/2090377629_Mikhail_Rudoy>Mikhail Rudoy</a>, <strong>Kai Xiao</strong>
              <br>
              <em>Oral Presentation at JCDCG^3</em>, 2017
              <br>
            </p>
            <p>
              Cookie Clicker is a popular online incremental game where the goal of the game is to generate as many cookies as possible. In the game you start with an initial cookie generation rate, and you can use cookies as currency to purchase various items that increase your cookie generation rate. In this paper, we analyze strategies for playing Cookie Clicker optimally. While simple to state, the game gives rise to interesting analysis involving ideas from NP-hardness, approximation algorithms, and dynamic programming.
            </p>
          </td>
        </tr>
        <tr id='mh'>
          <td width="30%">
            <img src="img/mh-cover-img.jpg" width="100%">
          </td>
          <td valign="top" width="70%">
            <p>
              <a href="https://arxiv.org/abs/1501.01720">
                Online Algorithms Modeled After Mousehunt
              </a>
              <br>
              <a href=https://www.linkedin.com/in/jeffrey-ling-92163879/>Jeffrey Ling</a>, <strong>Kai Xiao</strong>, <a href=https://www.linkedin.com/in/dai-yang-7983b363/>Dai Yang</a>
              <br>
            </p>
            <p>In this paper we study a variety of novel online algorithm problems inspired by the game Mousehunt. We consider a number of basic models that approximate the game, and we provide solutions to these models using Markov Decision Processes, deterministic online algorithms, and randomized online algorithms. We analyze these solutions' performance by deriving results on their competitive ratios.
            </p>
          </td>
        </tr>
      </tbody>
    </table>

    </div>
  </div>
  <div id = "hobbies">
    <div id = "hobbies-text">
    <h1> Hobbies </h1>
      In my spare time, I enjoy traveling. Some of my favorite cities to visit have been <a href="https://kaikaixiao.wordpress.com/2016/04/26/florence-love-story/">Florence</a>, <a href="https://kaikaixiao.wordpress.com/2016/02/21/copenhagen-and-malmo-who-needs-planning/">Copenhagen</a>, <a href="https://kaikaixiao.wordpress.com/2016/05/13/barcelona-and-madrid-colorful/">Barcelona</a>, and <a href="https://traveldiaristblog.wordpress.com/2017/06/27/kyoto-day-27-628/">Kyoto</a>.
      <br />
      <br />
      <br />
      I also enjoy dancing, especially hip-hop and K-pop dance. Sometimes I dance in fun cover videos of K-pop groups with my friends from the MIT Asian Dance Team and Eclipse K-pop - <a href="https://www.youtube.com/watch?v=sLnmAJLyA1c">like</a> <a href="https://www.youtube.com/watch?v=0EbTlTUy45w">in</a> <a href="https://www.youtube.com/watch?v=PIGSmlhqBAE">these</a> <a href="https://www.youtube.com/watch?v=jWWpH4k-y3c">five</a> <a href="https://www.youtube.com/watch?v=0Eh9fcjhQ84">videos</a>.
    </div>
    <div id = "inspirationalquote"><h2>It's a magical world, Hobbes, ol' buddy... Let's go exploring!</h2></div>

    <div id="copyright">
      Kai Xiao &#169 2020
    </div>
  </div>
  </body>
</html>
